{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f57144c4-8dae-44b5-a2bb-7172381fec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "api key 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\n",
      "path C:\\Users\\nonak\\Documents\\Thoughts\\Atlas\\03_SNIPPETS\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Coletando arquivos Markdown...\n",
      "‚úÖ 5 arquivos encontrados.\n",
      "\n",
      "\n",
      "üóìÔ∏è Data: 2025-05-03\n",
      "====================================================================================================\n",
      "\n",
      "üìÑ Resumo do arquivo: snip-openai-agent-llm-classificacao-v-df-pandas.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **T√≠tulo**: Cria√ß√£o de um Agente de Classifica√ß√£o de Colunas em DataFrames Pandas\n",
      "- **Principais t√≥picos**:\n",
      "  - Fun√ß√£o `classificar_dataframe` para classificar textos em um DataFrame usando a API da OpenAI\n",
      "  - Par√¢metros da fun√ß√£o e suas descri√ß√µes\n",
      "  - Processamento em lote ou individualmente\n",
      "  - Solicita√ß√£o de inputs do usu√°rio para chave de API e prompt do sistema\n",
      "  - Utiliza√ß√£o de prompt padr√£o se o usu√°rio n√£o fornecer um\n",
      "  - Classifica√ß√£o de um DataFrame com base em texto e sentimento\n",
      "- **Ideias centrais ou insights**:\n",
      "  - Fun√ß√£o que classifica textos em um DataFrame usando a API da OpenAI, preenchendo uma coluna de classifica√ß√£o\n",
      "  - Configura√ß√£o do modelo da OpenAI, instru√ß√£o do sistema, aleatoriedade das respostas e tamanho do lote de processamento\n",
      "  - Possibilidade de inserir chave de API e prompt personalizado\n",
      "  - Utiliza√ß√£o de prompt padr√£o para classificar texto como positivo, neutro ou negativo se n√£o houver input do usu√°rio\n",
      "  - Exibi√ß√£o do resultado da classifica√ß√£o no DataFrame\n",
      "- **Refer√™ncias importantes**:\n",
      "  - [[hub-llm]]\n",
      "  - [[hub-python]]\n",
      "  - [[Atlas/02_CONCEPT/criando-variaveis-(colunas)-em-um-dataframe.md|criando-variaveis-(colunas)-em-um-dataframe]]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üóìÔ∏è Data: 2025-05-02\n",
      "====================================================================================================\n",
      "\n",
      "üìÑ Resumo do arquivo: snip-andas-groupby-function.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais t√≥picos**:\n",
      "  - Criar agrupamento de vari√°veis em um DataFrame usando Pandas.\n",
      "\n",
      "- **Ideias centrais ou insights**:\n",
      "  - O c√≥digo apresentado demonstra como utilizar a fun√ß√£o `groupby` do Pandas para agrupar vari√°veis em um DataFrame.\n",
      "\n",
      "- **Refer√™ncias importantes**:\n",
      "  - [Documenta√ß√£o oficial do Pandas sobre a fun√ß√£o `groupby`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)\n",
      "  - Conex√£o com o t√≥pico \"[[grouping-data-by-category-in-pandas]]\"\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: snip-get-dataframe-info.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais t√≥picos**\n",
      "    - Obten√ß√£o de informa√ß√µes b√°sicas de um dataframe.\n",
      "    - Dimens√µes, tipos de dados, valores nulos, valores √∫nicos e estat√≠sticas descritivas.\n",
      "  \n",
      "- **Ideias centrais ou insights**\n",
      "    - O c√≥digo fornece um relat√≥rio informativo sobre um DataFrame, incluindo dimens√µes, tipos de dados, valores nulos, valores √∫nicos e estat√≠sticas descritivas.\n",
      "  \n",
      "- **Refer√™ncias importantes**\n",
      "    - [[hub-tratamento-de-dados]]\n",
      "    - [[hub-jupyterNotebook]]\n",
      "    - [[Extraindo informacoes dados]]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: snip-listar-diretorios-os.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **T√≠tulo**: Listar todos os arquivos em um diret√≥rio\n",
      "- **Principais t√≥picos**: \n",
      "  - Prop√≥sito de listar arquivos em um diret√≥rio\n",
      "  - C√≥digo em Python para listar arquivos\n",
      "  - Tratamento de exce√ß√µes para diret√≥rio n√£o encontrado ou permiss√£o negada\n",
      "- **Ideias centrais ou insights**: \n",
      "  - O c√≥digo em Python apresentado permite listar todos os arquivos em um diret√≥rio especificado.\n",
      "  - √â poss√≠vel filtrar apenas os arquivos, excluindo os diret√≥rios.\n",
      "  - S√£o tratadas exce√ß√µes para casos de diret√≥rio n√£o encontrado, permiss√£o negada e outros erros inesperados.\n",
      "- **Refer√™ncias importantes**: \n",
      "  - Conex√£o com o arquivo [[Atlas/05_DOC/doc-pandas-methods.md|doc-pandas-methods]]\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: snip-obter-percentual-valores-df.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Prop√≥sito:** Obter valores percentuais e propor√ß√µes do DataFrame.\n",
      "- **C√≥digos:** Utiliza√ß√£o das fun√ß√µes `value_counts` e `cut` do Pandas para calcular percentuais por faixa.\n",
      "- **Ideias centrais:** A fun√ß√£o `calcular_percentual_por_faixa` categoriza os dados em intervalos, calcula o percentual de ocorr√™ncias em cada categoria e retorna os percentuais arredondados.\n",
      "- **Refer√™ncias importantes:** Uso do Pandas para manipula√ß√£o e an√°lise de dados.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================\n",
    "# CONFIGURA√á√ïES\n",
    "# ========================\n",
    "\n",
    "openai.api_key = input('api key') # substitua pela sua chave\n",
    "CAMINHO_PASTA = input('path')\n",
    "MAX_CHARS = 4000\n",
    "\n",
    "# ========================\n",
    "# FUN√á√ïES UTILIT√ÅRIAS\n",
    "# ========================\n",
    "\n",
    "def coletar_markdowns(diretorio_base):\n",
    "    arquivos_md = []\n",
    "    for raiz, _, arquivos in os.walk(diretorio_base):\n",
    "        for arquivo in arquivos:\n",
    "            if arquivo.endswith(\".md\"):\n",
    "                caminho_completo = os.path.join(raiz, arquivo)\n",
    "                data_modificacao = datetime.fromtimestamp(os.path.getmtime(caminho_completo)).date()\n",
    "                arquivos_md.append({\n",
    "                    \"caminho\": caminho_completo,\n",
    "                    \"data\": data_modificacao\n",
    "                })\n",
    "    return arquivos_md\n",
    "\n",
    "def carregar_conteudo_arquivos(lista_arquivos):\n",
    "    conteudos = []\n",
    "    for item in lista_arquivos:\n",
    "        caminho = item[\"caminho\"]\n",
    "        try:\n",
    "            with open(caminho, 'r', encoding='utf-8') as f:\n",
    "                conteudos.append({\n",
    "                    \"caminho\": caminho,\n",
    "                    \"data\": item[\"data\"],\n",
    "                    \"conteudo\": f.read()\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler {caminho}: {e}\")\n",
    "    return conteudos\n",
    "\n",
    "def resumir_com_openai(texto, caminho, parte=None):\n",
    "    titulo_arquivo = os.path.basename(caminho)\n",
    "    parte_info = f\" (Parte {parte})\" if parte else \"\"\n",
    "    prompt = textwrap.dedent(f\"\"\"\n",
    "        Voc√™ √© um assistente que resume arquivos Markdown de forma objetiva e concisa.\n",
    "        Resuma brevemente o conte√∫do do arquivo: **{titulo_arquivo}{parte_info}**.\n",
    "\n",
    "        Formato do resumo:\n",
    "        - **T√≠tulo** (se houver)\n",
    "        - **Principais t√≥picos**\n",
    "        - **Ideias centrais ou insights**\n",
    "        - **Refer√™ncias importantes (se houver)**\n",
    "        \n",
    "        Seja direto, use frases curtas e foque apenas no essencial.\n",
    "\n",
    "        Texto:\n",
    "        {texto}\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        resposta = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente que resume arquivos Markdown com precis√£o e concis√£o.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=400  # Resumo mais curto\n",
    "        )\n",
    "        return resposta['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"[ERRO AO CONSULTAR LLM]: {e}\"\n",
    "\n",
    "\n",
    "def dividir_texto(texto, max_chars):\n",
    "    partes = []\n",
    "    while len(texto) > max_chars:\n",
    "        corte = texto[:max_chars].rfind(\"\\n\\n\")\n",
    "        if corte == -1:\n",
    "            corte = max_chars\n",
    "        partes.append(texto[:corte])\n",
    "        texto = texto[corte:]\n",
    "    partes.append(texto)\n",
    "    return partes\n",
    "\n",
    "def processar_arquivo(item):\n",
    "    caminho = item[\"caminho\"]\n",
    "    texto = item[\"conteudo\"]\n",
    "\n",
    "    partes = dividir_texto(texto, MAX_CHARS)\n",
    "    resumos_parciais = []\n",
    "\n",
    "    for idx, parte in enumerate(partes):\n",
    "        resumo = resumir_com_openai(parte, caminho, parte=(idx+1) if len(partes) > 1 else None)\n",
    "        resumos_parciais.append(resumo)\n",
    "\n",
    "    if len(resumos_parciais) > 1:\n",
    "        resumo_final = resumir_com_openai(\"\\n\\n\".join(resumos_parciais), caminho)\n",
    "    else:\n",
    "        resumo_final = resumos_parciais[0]\n",
    "\n",
    "    return resumo_final\n",
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîç Coletando arquivos Markdown...\")\n",
    "    arquivos = coletar_markdowns(CAMINHO_PASTA)\n",
    "    print(f\"‚úÖ {len(arquivos)} arquivos encontrados.\\n\")\n",
    "\n",
    "    conteudos = carregar_conteudo_arquivos(arquivos)\n",
    "\n",
    "    # Agrupar arquivos por data\n",
    "    arquivos_por_data = defaultdict(list)\n",
    "    for item in conteudos:\n",
    "        arquivos_por_data[item[\"data\"]].append(item)\n",
    "\n",
    "    # Ordenar por data decrescente\n",
    "    datas_ordenadas = sorted(arquivos_por_data.keys(), reverse=True)\n",
    "\n",
    "    for data in datas_ordenadas:\n",
    "        print(f\"\\nüóìÔ∏è Data: {data}\")\n",
    "        print(\"=\" * 100)\n",
    "        for item in arquivos_por_data[data]:\n",
    "            print(f\"\\nüìÑ Resumo do arquivo: {os.path.basename(item['caminho'])}\")\n",
    "            print(\"-\" * 80)\n",
    "            resumo = processar_arquivo(item)\n",
    "            print(resumo)\n",
    "            print(\"\\n\" + \"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4285c7f-0b88-487a-8e9b-ac9ce2f6c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
