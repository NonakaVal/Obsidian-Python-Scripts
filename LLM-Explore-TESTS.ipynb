{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f57144c4-8dae-44b5-a2bb-7172381fec03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "api key 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\n",
      "path C:\\Users\\nonak\\Documents\\Thoughts\\Drafts\\LLM-searches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Coletando arquivos Markdown...\n",
      "‚úÖ 5 arquivos encontrados.\n",
      "\n",
      "\n",
      "üóìÔ∏è Data: 2025-04-14\n",
      "====================================================================================================\n",
      "\n",
      "üìÑ Resumo do arquivo: datascience-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **T√≠tulo:** Entendendo como interpretamos e compartilhamos desinforma√ß√£o\n",
      "- **Principais t√≥picos:** Susceptibilidade √† desinforma√ß√£o online, fatores demogr√°ficos, interpreta√ß√£o e compartilhamento de desinforma√ß√£o.\n",
      "- **Ideias centrais ou insights:** Explora a interpreta√ß√£o e compartilhamento de desinforma√ß√£o, contribuindo para estrat√©gias eficazes de desmascaramento.\n",
      "- **Refer√™ncias importantes:** [Entendendo como interpretamos e compartilhamos desinforma√ß√£o](https://www.psychologicalscience.org/publications/observer/interpret-share-misinformation.html)\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: datascience_content_ideas-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **T√≠tulo**: Perguntas sobre canais de YouTube de ci√™ncia de dados em 2024\n",
      "- **Principais t√≥picos**: Tend√™ncias, habilidades espec√≠ficas, intera√ß√£o com o p√∫blico, entrega de conte√∫do, aplica√ß√£o pr√°tica, atualiza√ß√£o, n√≠veis de habilidade, impacto na comunidade, colabora√ß√£o, formatos inovadores.\n",
      "- **Ideias centrais ou insights**: Canais de YouTube de ci√™ncia de dados em 2024 focam em atualiza√ß√£o, conte√∫do pr√°tico, colabora√ß√£o e diversidade de habilidades.\n",
      "- **Refer√™ncias importantes**: Canais como 3Blue1Brown, Joma Tech e CS Dojo s√£o fontes relevantes de conte√∫do em ci√™ncia de dados e programa√ß√£o.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: data_science_projetc-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais t√≥picos**:\n",
      "  - Listas de projetos de ci√™ncia de dados para iniciantes e especialistas.\n",
      "  - Ideias de projetos de fontes variadas como Built In, 365 Data Science, Reddit, GeeksforGeeks, Springboard, Medium, StrataScratch e Quora.\n",
      "  - Sugest√µes de projetos para portf√≥lios e iniciantes.\n",
      "  - Orienta√ß√£o pr√°tica, conjuntos de dados, artigos de pesquisa, elementos interativos e recursos adicionais para explora√ß√£o.\n",
      "  - Desafios comuns na implementa√ß√£o de projetos de ci√™ncia de dados, ideias inovadoras para 2025, uso de tecnologias emergentes e tend√™ncias na ci√™ncia de dados.\n",
      "  - Contribui√ß√£o dos projetos de ci√™ncia de dados na resolu√ß√£o de desafios do mundo real, habilidades e ferramentas essenciais, manter-se atualizado com confer√™ncias e eventos, e principais ideias de projetos com c√≥digo-fonte.\n",
      "\n",
      "- **Ideias centrais ou insights**:\n",
      "  - Diversidade de projetos de ci√™ncia de dados para diferentes n√≠veis de habilidade e interesses.\n",
      "  - Import√¢ncia da relev√¢ncia no mundo real dos projetos para melhorar a experi√™ncia de aprendizado.\n",
      "  - Enfoque em solu√ß√µes eficazes para desafios comuns, ideias inovadoras para 2025, utiliza√ß√£o de tecnologias emergentes e contribui√ß√£o dos projetos na sociedade.\n",
      "\n",
      "- **Refer√™ncias importantes**:\n",
      "  - Built In, 365 Data Science, Reddit, GeeksforGeeks, Springboard, Medium, StrataScratch, ProjectPro.io.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: mental_health-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **Principais t√≥picos**:\n",
      "  - Benef√≠cios do compartilhamento de conhecimento\n",
      "  - Import√¢ncia do compartilhamento de conhecimento\n",
      "  - Exemplos e benef√≠cios espec√≠ficos de compartilhamento de conhecimento\n",
      "\n",
      "- **Ideias centrais ou insights**:\n",
      "  - Compartilhar conhecimento alinha equipes, engaja funcion√°rios e promove inova√ß√£o.\n",
      "  - O compartilhamento de conhecimento padroniza procedimentos e cria especialistas.\n",
      "  - Compartilhar conhecimento melhora o crescimento pessoal e profissional.\n",
      "\n",
      "- **Refer√™ncias importantes**:\n",
      "  - Links para artigos sobre a import√¢ncia e benef√≠cios do compartilhamento de conhecimento.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìÑ Resumo do arquivo: mental_helth-complete-ptbr.md\n",
      "--------------------------------------------------------------------------------\n",
      "- **T√≠tulo**: Diversos t√≠tulos abordando a exposi√ß√£o da vida pessoal online.\n",
      "- **Principais t√≥picos**: Motiva√ß√µes para compartilhar a vida pessoal online, equil√≠brio entre autenticidade e privacidade, impacto nos relacionamentos, import√¢ncia da auto-revela√ß√£o online.\n",
      "- **Ideias centrais ou insights**: Encontrar equil√≠brio na exposi√ß√£o online, reflex√£o sobre os motivos e impactos do compartilhamento, prote√ß√£o dos relacionamentos pessoais.\n",
      "- **Refer√™ncias importantes**: Scott Stratten, Scientific American, Medium, Fox Business, artigo de Lada Prkic.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "import textwrap\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# ========================\n",
    "# CONFIGURA√á√ïES\n",
    "# ========================\n",
    "\n",
    "openai.api_key = input('api key') # substitua pela sua chave\n",
    "CAMINHO_PASTA = input('path')\n",
    "MAX_CHARS = 4000\n",
    "\n",
    "# ========================\n",
    "# FUN√á√ïES UTILIT√ÅRIAS\n",
    "# ========================\n",
    "\n",
    "def coletar_markdowns(diretorio_base):\n",
    "    arquivos_md = []\n",
    "    for raiz, _, arquivos in os.walk(diretorio_base):\n",
    "        for arquivo in arquivos:\n",
    "            if arquivo.endswith(\".md\"):\n",
    "                caminho_completo = os.path.join(raiz, arquivo)\n",
    "                data_modificacao = datetime.fromtimestamp(os.path.getmtime(caminho_completo)).date()\n",
    "                arquivos_md.append({\n",
    "                    \"caminho\": caminho_completo,\n",
    "                    \"data\": data_modificacao\n",
    "                })\n",
    "    return arquivos_md\n",
    "\n",
    "def carregar_conteudo_arquivos(lista_arquivos):\n",
    "    conteudos = []\n",
    "    for item in lista_arquivos:\n",
    "        caminho = item[\"caminho\"]\n",
    "        try:\n",
    "            with open(caminho, 'r', encoding='utf-8') as f:\n",
    "                conteudos.append({\n",
    "                    \"caminho\": caminho,\n",
    "                    \"data\": item[\"data\"],\n",
    "                    \"conteudo\": f.read()\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao ler {caminho}: {e}\")\n",
    "    return conteudos\n",
    "\n",
    "def resumir_com_openai(texto, caminho, parte=None):\n",
    "    titulo_arquivo = os.path.basename(caminho)\n",
    "    parte_info = f\" (Parte {parte})\" if parte else \"\"\n",
    "    prompt = textwrap.dedent(f\"\"\"\n",
    "        Voc√™ √© um assistente que resume arquivos Markdown de forma objetiva e concisa.\n",
    "        Resuma brevemente o conte√∫do do arquivo: **{titulo_arquivo}{parte_info}**.\n",
    "\n",
    "        Formato do resumo:\n",
    "        - **T√≠tulo** (se houver)\n",
    "        - **Principais t√≥picos**\n",
    "        - **Ideias centrais ou insights**\n",
    "        - **Refer√™ncias importantes (se houver)**\n",
    "        \n",
    "        Seja direto, use frases curtas e foque apenas no essencial.\n",
    "\n",
    "        Texto:\n",
    "        {texto}\n",
    "    \"\"\")\n",
    "\n",
    "    try:\n",
    "        resposta = openai.ChatCompletion.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"Voc√™ √© um assistente que resume arquivos Markdown com precis√£o e concis√£o.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            temperature=0.2,\n",
    "            max_tokens=400  # Resumo mais curto\n",
    "        )\n",
    "        return resposta['choices'][0]['message']['content']\n",
    "    except Exception as e:\n",
    "        return f\"[ERRO AO CONSULTAR LLM]: {e}\"\n",
    "\n",
    "\n",
    "def dividir_texto(texto, max_chars):\n",
    "    partes = []\n",
    "    while len(texto) > max_chars:\n",
    "        corte = texto[:max_chars].rfind(\"\\n\\n\")\n",
    "        if corte == -1:\n",
    "            corte = max_chars\n",
    "        partes.append(texto[:corte])\n",
    "        texto = texto[corte:]\n",
    "    partes.append(texto)\n",
    "    return partes\n",
    "\n",
    "def processar_arquivo(item):\n",
    "    caminho = item[\"caminho\"]\n",
    "    texto = item[\"conteudo\"]\n",
    "\n",
    "    partes = dividir_texto(texto, MAX_CHARS)\n",
    "    resumos_parciais = []\n",
    "\n",
    "    for idx, parte in enumerate(partes):\n",
    "        resumo = resumir_com_openai(parte, caminho, parte=(idx+1) if len(partes) > 1 else None)\n",
    "        resumos_parciais.append(resumo)\n",
    "\n",
    "    if len(resumos_parciais) > 1:\n",
    "        resumo_final = resumir_com_openai(\"\\n\\n\".join(resumos_parciais), caminho)\n",
    "    else:\n",
    "        resumo_final = resumos_parciais[0]\n",
    "\n",
    "    return resumo_final\n",
    "\n",
    "# ========================\n",
    "# MAIN\n",
    "# ========================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"üîç Coletando arquivos Markdown...\")\n",
    "    arquivos = coletar_markdowns(CAMINHO_PASTA)\n",
    "    print(f\"‚úÖ {len(arquivos)} arquivos encontrados.\\n\")\n",
    "\n",
    "    conteudos = carregar_conteudo_arquivos(arquivos)\n",
    "\n",
    "    # Agrupar arquivos por data\n",
    "    arquivos_por_data = defaultdict(list)\n",
    "    for item in conteudos:\n",
    "        arquivos_por_data[item[\"data\"]].append(item)\n",
    "\n",
    "    # Ordenar por data decrescente\n",
    "    datas_ordenadas = sorted(arquivos_por_data.keys(), reverse=True)\n",
    "\n",
    "    for data in datas_ordenadas:\n",
    "        print(f\"\\nüóìÔ∏è Data: {data}\")\n",
    "        print(\"=\" * 100)\n",
    "        for item in arquivos_por_data[data]:\n",
    "            print(f\"\\nüìÑ Resumo do arquivo: {os.path.basename(item['caminho'])}\")\n",
    "            print(\"-\" * 80)\n",
    "            resumo = processar_arquivo(item)\n",
    "            print(resumo)\n",
    "            print(\"\\n\" + \"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4285c7f-0b88-487a-8e9b-ac9ce2f6c49e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
